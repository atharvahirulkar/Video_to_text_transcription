Today’s world, where the demand for video content is rapidly increasing, the use of subtitles and text has become important for understanding the video. The need for answers for how video should be transcribed has intensified with the accessibility and usage of video recording in contemporary empirical social science research.The goal is to caption the videos that are now playing. This work eliminates the need to pause, write text, and repeat while watching a video to understand its contents. Additionally, the goal meets the requirements of those who have hearing problems. For individuals who are deaf, visually impaired, struggle with reading and literacy, as well as others who are just starting to read, transcription is crucial. For those who have trouble understanding the verbal and auditory components of the visual, video transcriptions offer information.


Pre-saved video to be uploaded in any format viz. .mov, .mkv,  .wav formats on the website so as to be transcribed according to individuals’ need. Once uploaded, the video is fetched through the algorithm where the wave library separates the audio from the video so as to be processed through the HMM. This particular model makes use of pre-trained librosa libraries for recognition.
The speech recognition model aftering running through the model transcribes the audio file to a text inscription. Once done, the transcribed text makes use of hugging face transformers for summarization of the textual contents. Additionally, the transcription can be obtained in multiple languages owing to the users’ requirements.
